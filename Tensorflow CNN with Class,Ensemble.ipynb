{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow CNN with Class,Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import os\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=20\n",
    "batch_size=100\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        self.training= tf.placeholder(tf.bool)\n",
    "        self.X = tf.placeholder(tf.float32,[None, 784])\n",
    "        X_img = tf.reshape(self.X, [-1,28,28,1])\n",
    "        self.Y = tf.placeholder(tf.float32,[None,10])\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(inputs = X_img, filters = 32, kernel_size=[3,3], padding = \"SAME\", activation=tf.nn.relu)\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "        drop1 = tf.layers.dropout(inputs=pool1, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(inputs = drop1, filters = 64, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.relu)\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "        drop2 = tf.layers.dropout(inputs=pool2, rate=0.7, training = self.training)\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(inputs = drop2, filters = 128, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.relu)\n",
    "        pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size = [2, 2], padding=\"SAME\", strides=2)\n",
    "        drop3 = tf.layers.dropout(inputs=pool3, rate=0.7, training = self.training)\n",
    "        \n",
    "        flat = tf.reshape(drop3, [-1,128*4*4])\n",
    "        dense4 = tf.layers.dense(inputs=flat,units=625,activation=tf.nn.relu,kernel_initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "        drop4 = tf.layers.dropout(inputs=dense4,rate=0.6,training = self.training)\n",
    "        batch4 = tf.layers.batch_normalization(drop4,training= True)\n",
    "\n",
    "        dense5 = tf.layers.dense(inputs=batch4,units=200,activation=tf.nn.relu,kernel_initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "        drop5 = tf.layers.dropout(inputs=dense5,rate=0.6,training = self.training)\n",
    "        batch5 = tf.layers.batch_normalization(drop5,training= True)\n",
    "        \n",
    "        self.logits = tf.layers.dense(inputs=batch5,units=10)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits,1),tf.argmax(self.Y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        \n",
    "        \n",
    "    def predict(self,x_test,training=False):\n",
    "        return self.sess.run(self.logits,feed_dict={self.X:x_test, self.training:training})\n",
    "        \n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,feed_dict={self.X:x_test, self.Y:y_test, self.training:training})\n",
    "        \n",
    "    def train(self,x_test,y_test,training=True):\n",
    "        return self.sess.run([self.cost,self.optimizer],feed_dict={self.X:x_test,self.Y:y_test, self.training:training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "models=[]\n",
    "num_models=7\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess,\"model\"+str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start!!\n",
      "epoch :  0001  cost :  [ 1.48335613  1.46950979  1.44522729  1.45866581  1.43859874  1.49825155\n",
      "  1.41484424]\n",
      "epoch :  0002  cost :  [ 0.61674833  0.59948313  0.61801164  0.6070387   0.60974949  0.61686311\n",
      "  0.6000339 ]\n",
      "epoch :  0003  cost :  [ 0.44496018  0.42917468  0.44364652  0.47278734  0.48406952  0.44436493\n",
      "  0.44767544]\n",
      "epoch :  0004  cost :  [ 0.36205577  0.350574    0.35321389  0.38492298  0.40116563  0.36066929\n",
      "  0.37510111]\n",
      "epoch :  0005  cost :  [ 0.3126456   0.30432752  0.30606643  0.32713716  0.34002169  0.30535766\n",
      "  0.32183612]\n",
      "epoch :  0006  cost :  [ 0.28687012  0.27487363  0.2782214   0.29522714  0.30476598  0.2781608\n",
      "  0.28944802]\n",
      "epoch :  0007  cost :  [ 0.26373795  0.25783114  0.26067793  0.2721159   0.27729029  0.25647446\n",
      "  0.2720459 ]\n",
      "epoch :  0008  cost :  [ 0.24660888  0.24129316  0.23959809  0.25653652  0.25648285  0.23670561\n",
      "  0.24990426]\n",
      "epoch :  0009  cost :  [ 0.22661195  0.22285208  0.22734903  0.237676    0.24159321  0.22382934\n",
      "  0.23567546]\n",
      "epoch :  0010  cost :  [ 0.21502795  0.21432062  0.21755981  0.22454436  0.22863039  0.21246751\n",
      "  0.22555399]\n",
      "epoch :  0011  cost :  [ 0.21214367  0.20871802  0.20989997  0.21302634  0.21554521  0.21162275\n",
      "  0.21490688]\n",
      "epoch :  0012  cost :  [ 0.20157703  0.20033741  0.19833105  0.21167265  0.21651144  0.19634331\n",
      "  0.21132211]\n",
      "epoch :  0013  cost :  [ 0.19063303  0.19636631  0.19593429  0.19563826  0.20783202  0.1933037\n",
      "  0.20079309]\n",
      "epoch :  0014  cost :  [ 0.18694328  0.18319508  0.18456176  0.19276523  0.19347116  0.18687442\n",
      "  0.18935511]\n",
      "epoch :  0015  cost :  [ 0.18160795  0.17949751  0.18079524  0.18514113  0.18996195  0.17928132\n",
      "  0.19040588]\n",
      "epoch :  0016  cost :  [ 0.17654376  0.17335589  0.17380483  0.18219717  0.18740409  0.17404583\n",
      "  0.18198966]\n",
      "epoch :  0017  cost :  [ 0.17325999  0.17650539  0.17187211  0.17830594  0.1774472   0.16884606\n",
      "  0.17843683]\n",
      "epoch :  0018  cost :  [ 0.16737694  0.1661695   0.16754082  0.17818367  0.17614638  0.16578297\n",
      "  0.17450047]\n",
      "epoch :  0019  cost :  [ 0.16251972  0.16866764  0.1671723   0.16534653  0.17811233  0.16745805\n",
      "  0.16765913]\n",
      "epoch :  0020  cost :  [ 0.15924307  0.16336552  0.16082523  0.16630538  0.17298564  0.15969729\n",
      "  0.1686938 ]\n",
      "Learning finished!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning start!!\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        for m_idx,m in enumerate(models):\n",
    "            c,_ = m.train(batch_xs,batch_ys)\n",
    "            avg_cost_list[m_idx] += c/total_batch\n",
    "    print(\"epoch : \", \"%04d\"%(epoch+1), \" cost : \", avg_cost_list)\n",
    "    \n",
    "print(\"Learning finished!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accuracy =  0.99\n",
      "1 Accuracy =  0.9934\n",
      "2 Accuracy =  0.9912\n",
      "3 Accuracy =  0.991\n",
      "4 Accuracy =  0.9896\n",
      "5 Accuracy =  0.991\n",
      "6 Accuracy =  0.9918\n",
      "Ensemble Accuracy =  0.9914\n"
     ]
    }
   ],
   "source": [
    "sample_data = mnist.test.images[5000:10000]\n",
    "sample_label = mnist.test.labels[5000:10000]\n",
    "\n",
    "\n",
    "test_size = len(sample_label)\n",
    "prediction = np.zeros(test_size*10).reshape(test_size,10)\n",
    "\n",
    "for m_idx,m in enumerate(models):\n",
    "    print(m_idx, \"Accuracy = \", m.get_accuracy(sample_data,sample_label))\n",
    "    p = m.predict(sample_data)\n",
    "    prediction +=p\n",
    "\n",
    "ensemble_correct = tf.equal(tf.argmax(prediction,1),tf.argmax(sample_label,1))\n",
    "ensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct,tf.float32))\n",
    "\n",
    "print(\"Ensemble Accuracy = \", sess.run(ensemble_accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow35]",
   "language": "python",
   "name": "conda-env-tensorflow35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
